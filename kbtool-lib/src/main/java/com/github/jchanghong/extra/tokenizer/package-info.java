/**
 * 中文分词封装<br>
 * 通过定义统一接口，适配第三方分词引擎
 * 
 * @author looly
 *
 */
package com.github.jchanghong.extra.tokenizer;